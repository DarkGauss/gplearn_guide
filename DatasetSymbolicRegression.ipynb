{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for gplearn and pydotplus in order to see graph view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from gplearn.fitness import make_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Import the required libraries--\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#--debug mode to report on evaluation of tree--\n",
    "debug_eval = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Scipy generic dataset \n",
    "* Number of Instances:506\n",
    "* Number of Attributes:13\n",
    "* Attribute Information (in order):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<li>CRIM     per capita crime rate by town</li>\n",
    "<li>ZN       proportion of residential land zoned for lots over 25,000 sq.ft.</li>\n",
    "<li>INDUS    proportion of non-retail business acres per town</li>\n",
    "<li>CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)</li>\n",
    "<li>NOX      nitric oxides concentration (parts per 10 million)</li>\n",
    "<li>RM       average number of rooms per dwelling</li>\n",
    "<li>AGE      proportion of owner-occupied units built prior to 1940</li>\n",
    "<li>DIS      weighted distances to five Boston employment centres</li>\n",
    "<li>RAD      index of accessibility to radial highways</li>\n",
    "<li>TAX      full-value property-tax rate per \\\\$10,000</li>\n",
    "<li>PTRATIO  pupil-teacher ratio by town</li>\n",
    "<li>B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town</li>\n",
    "<li>LSTAT    \\\\% lower status of the population</li>\n",
    "<li>MEDV     Median value of owner-occupied homes in $1000’s</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      " data_x:(506, 13)\n",
      " data_y:(506,)\n",
      " train_x:(404, 13)\n",
      " test_x:(102, 13)\n",
      " train_y:(404,)\n",
      " test_y:(102,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "#load the data from the default data set, and split it into a tuple\n",
    "data = load_boston(return_X_y = True)\n",
    "\n",
    "#what percent of our data do we want to use to validate\n",
    "split_percent = 0.2\n",
    "train_x, test_x, train_y, test_y = train_test_split(*data, test_size = split_percent, random_state = 0)\n",
    "\n",
    "#print out the shapes for clarity\n",
    "print(\"Shapes:\\n data_x:{}\\n data_y:{}\\n train_x:{}\\n test_x:{}\\n train_y:{}\\n test_y:{}\"\n",
    "      .format(data[0].shape,data[1].shape,train_x.shape,test_x.shape,train_y.shape,test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic regression\n",
    "\n",
    "We run a symbolic regression on a 1000 individuals for 20 generations. There are three kinds of mutation, subtree, hoist, and point. The hoist mutation is the only type that differs significantly from what was talked about in class. In it, a random subtree is selected, then, a random subtree from within it is lifted to it’s root node. It is used to combat tree bloat, and it appears to be very effective. Without the hoist mutation, tree trees grew like redwoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |    Population Average   |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    18.39 3931369986002.4434        5 7.405075814309804 8.075799745618673     51.99s\n",
      "   1     6.46 4277423.525192768       24 6.078022707279818 6.105147554124325      9.13m\n",
      "   2      5.4 143.87782647919852       24 5.685162977936526 6.855180318004764     13.01m\n",
      "   3     6.81 1386.0260507911844       26 5.241415543637552 7.2254326636846224     14.88m\n",
      "   4     7.76 280.0639664766024       11 5.270680740203347 6.180452013360248     16.12m\n",
      "   5    11.74 180.72981832106476       24 5.160452603983904 5.966489709315549     17.02m\n",
      "   6    18.56 273.5285434394705       11 4.78794942210678 6.741768154362778     17.88m\n",
      "   7    27.72 260.94217963947665       49 4.743968034216383 5.414616563096804     18.86m\n",
      "   8     32.7 259.81546085673307       24 4.323180986834434 5.8019536551707915     20.08m\n",
      "   9    36.46 220.66032058357132       76 4.3266753460389005 5.759308727515377     21.22m\n",
      "  10    39.84 116.58991565523888       93 4.389424516371594 5.896427543131075     22.21m\n",
      "  11    45.32 135.54654189399903       57 4.215806469180731 5.972727427647123     22.97m\n",
      "  12    52.46 64.13591984700966       91 4.230323585172565 6.100525206265836     23.65m\n",
      "  13    58.54 61.78180819504972       35 4.072424151304985 6.042011345687683     24.36m\n"
     ]
    }
   ],
   "source": [
    "#This part sets up the symbolic regressor\n",
    "est_gp = SymbolicRegressor(population_size=10000,\n",
    "                           generations=40, stopping_criteria=0,\n",
    "                           p_crossover=0.9, p_subtree_mutation=0.01,\n",
    "                           p_hoist_mutation=0.01, p_point_mutation=0.01,\n",
    "                           max_samples=0.6, verbose=1,\n",
    "                           parsimony_coefficient=0.001, random_state=0,\n",
    "                           metric = 'rmse',\n",
    "                           function_set=('add', 'sub', 'mul', 'div',\"sin\"),\n",
    "                           n_jobs = 10\n",
    "                           )\n",
    "#This part runs it on our data\n",
    "est_gp.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring\n",
    "Returns the coefficient of determination R^2 of the prediction.\n",
    "\n",
    "The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(best_gp._program)\n",
    "best_gp.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pydotplus.graphviz.graph_from_dot_data(best_gp._program.export_graphviz())\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
